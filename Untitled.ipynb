{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ed401-8ded-4ad2-b818-838b94973d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "grad = torch.tensor([[-0.3623, -0.6115],\n",
    "        [ 0.7283,  0.4699],\n",
    "        [ 2.3261,  0.1599]])\n",
    "\n",
    "U = torch.tensor(np.ones((2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1b69e-274e-44f7-8173-570fa6257d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5382d9dc-56d1-4d54-90b3-00d62f7e1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef246cba-dd2f-4ef6-a4ba-33795c5b69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = torch.sqrt(torch.sum(grad * grad / U, dim=1))\n",
    "#pred = torch.normal(pred.view(-1), sigma.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b56e7-d521-4e88-8130-225fad9121df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812e1d1d-bf0e-442c-9db4-30b049841739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557c89f-8167-4190-aae7-8281d8fa0ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "grad = torch.rand(64,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9bda7-22d5-4490-8743-aa3911344da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46353e-ebba-427b-ae92-7acb246e6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.sum(torch.bmm(grad.unsqueeze(2),grad.unsqueeze(2).permute(0,2,1)),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32801d8-8704-4785-910c-537772697f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82256c-7bfe-44c5-b6ce-66821e946d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5788e-d3c3-4e17-ae26-4ce90f552267",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.tensor([1,2,3])\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eca1129-29eb-4d4b-bae4-dbbfb1aa7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "res= torch.mul(s.unsqueeze(1),s.unsqueeze(1).permute(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df236c4c-391f-473d-a602-cbff606a0a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafe64f-dab5-48af-a9f5-68ef51b7ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = torch.rand(9,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a500756-59a2-4319-b0cd-d42ceb6a2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my = torch.sum(torch.bmm(torch.matmul(grad.unsqueeze(2).permute(0,2,1), torch.inverse(U)),grad.unsqueeze(2)).squeeze(2),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a525a-8cdf-4828-8db9-767a28cc46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742dffd4-544e-4d9d-9761-7ff64d3ea758",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.eye(5)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae198c8-429e-413f-94cc-c5b713050dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b4fb21-dcd5-4773-ad8a-6934f36d6c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "class NeuralTS(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_k=6, nu=1, lamdba=1):\n",
    "        super(NeuralTS, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_k = embedding_k\n",
    "        self.nu = nu\n",
    "        self.lamdba = lamdba\n",
    "        self.W = torch.nn.Linear(self.num_users, self.embedding_k, bias=False).cuda()\n",
    "        self.H = torch.nn.Linear(self.num_items, self.embedding_k, bias=False).cuda()\n",
    "        self.linear_1 = torch.nn.Linear(12, 16).cuda()\n",
    "        self.linear_2 = torch.nn.Linear(16, 8).cuda()\n",
    "        self.linear_3 = torch.nn.Linear(9, 1, bias=False).cuda()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "        self.xent_func = torch.nn.BCELoss()\n",
    "        self.param = list(self.parameters())\n",
    "        print(self.param)\n",
    "        self.U = lamdba * torch.tensor(np.ones(9)).cuda()\n",
    "\n",
    "    def forward(self, x_user, x_item):\n",
    "        U_emb = self.W(x_user)\n",
    "        V_emb = self.H(F.one_hot(x_item, num_classes=self.num_items).float())\n",
    "        z_emb = torch.cat([U_emb, V_emb], axis=1)\n",
    "        h1 = self.linear_1(z_emb)\n",
    "        h1 = self.relu(h1)\n",
    "        h2 = self.linear_2(h1)\n",
    "        h2 = self.relu(h2)\n",
    "        h2 = torch.cat((h2, torch.Tensor(np.ones((h2.size()[0],1))).cuda()),1)\n",
    "        out = self.linear_3(h2)\n",
    "        return out, h2\n",
    "\n",
    "    def fit(self, x_user, x_item, y, num_epoch=1, lamb=0, lr=0.01, batch_size=64):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=lamb)\n",
    "        last_loss = 1e9\n",
    "        num_sample = len(x_user)\n",
    "        total_batch = num_sample // batch_size\n",
    "        early_stop = 0\n",
    "\n",
    "        for epoch in range(num_epoch):\n",
    "            all_idx = np.arange(num_sample)\n",
    "            epoch_loss = 0\n",
    "            for idx in range(total_batch):\n",
    "                selected_idx = all_idx[batch_size*idx:(idx+1)*batch_size]\n",
    "                sub_x_user = x_user[selected_idx]\n",
    "                sub_x_item = x_item[selected_idx]\n",
    "                sub_y = y[selected_idx]\n",
    "                optimizer.zero_grad()\n",
    "                if not torch.is_tensor(sub_x_user):\n",
    "                    sub_x_user = torch.Tensor(sub_x_user).cuda()\n",
    "                if not torch.is_tensor(sub_x_item):\n",
    "                    sub_x_item = torch.LongTensor(sub_x_item).cuda()\n",
    "                if not torch.is_tensor(sub_y):\n",
    "                    sub_y = torch.Tensor(sub_y).cuda()\n",
    "                pred, grad = self.forward(sub_x_user,sub_x_item)\n",
    "                pred = self.sigmoid(pred)\n",
    "                loss = self.xent_func(pred.float(), torch.unsqueeze(sub_y.float(),1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.cpu().detach().numpy()                \n",
    "            relative_loss_div = (last_loss-epoch_loss)/(last_loss+1e-10)\n",
    "            last_loss = epoch_loss\n",
    "\n",
    "        all_idx = np.arange(num_sample)\n",
    "        for idx in range(total_batch):\n",
    "            selected_idx = all_idx[batch_size*idx:(idx+1)*batch_size]\n",
    "            sub_x_user = x_user[selected_idx]\n",
    "            sub_x_item = x_item[selected_idx]\n",
    "            sub_y = y[selected_idx]\n",
    "            optimizer.zero_grad()\n",
    "            if not torch.is_tensor(sub_x_user):\n",
    "                sub_x_user = torch.Tensor(sub_x_user).cuda()\n",
    "            if not torch.is_tensor(sub_x_item):\n",
    "                sub_x_item = torch.LongTensor(sub_x_item).cuda()\n",
    "            if not torch.is_tensor(sub_y):\n",
    "                sub_y = torch.Tensor(sub_y).cuda()\n",
    "            with torch.no_grad():\n",
    "                _, grad = self.forward(sub_x_user,sub_x_item)\n",
    "            self.U += torch.sum(grad*grad, dim=0) \n",
    "        \n",
    "    def predict(self, x_user, x_item):\n",
    "        with torch.no_grad():\n",
    "            if not torch.is_tensor(x_user):\n",
    "                x_user = torch.Tensor(x_user).cuda()\n",
    "            if not torch.is_tensor(x_item):\n",
    "                x_item = torch.LongTensor(x_item).cuda()\n",
    "            pred, grad = self.forward(x_user, x_item)\n",
    "            sigma = torch.sqrt(torch.sum(self.lamdba * self.nu * grad * grad / self.U, dim=1))\n",
    "            #tmp = torch.sqrt(torch.sum(self.lamdba * self.nu * grad * grad / self.U, dim=1))\n",
    "            #sigma =torch.ones_like(tmp)*0.2\n",
    "            print(sigma.shape)\n",
    "            pred = torch.normal(pred.view(-1), sigma.view(-1))\n",
    "            pred = self.sigmoid(pred)\n",
    "            res_pred = pred.cpu().detach().numpy().flatten()\n",
    "        return res_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4abf8e0-5b83-445c-aa38-bc740862f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralTS(num_users=136, num_items=653, embedding_k=6, nu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aacf4e-bce0-4e00-bb39-d22967cd3412",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50fc69-6d4d-439b-887f-3bab640f8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.param = [x.grad.view(-1) for x in model.param]\n",
    "shape = [x.shape for x in model.param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c87f3a-8b91-45a3-99cb-0ac478cfa6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001e858-91fd-4c8e-8e28-9e77a9a27a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = torch.cat(model.param,dim=0)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5299290e-a610-40f3-9f56-4b08226eaf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4a746-4aec-4fd3-8a95-771f7d1ba933",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.param[0]\n",
    "for i in range(len(model.param)-1):\n",
    "    res = torch.cat(res,model.param[i+1],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb260ac5-26fc-4bf3-b086-9bd8146b6e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817633cb-1d4c-4169-8995-30b985d89e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd32272-13ca-4a35-91de-8db894734faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bdc6ae-7a1a-4494-8626-83e382d754b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde6b16-e142-437b-8155-de4e75df66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def listToTensor():\n",
    "    tensor1=torch.tensor([1,2,3])\n",
    "    tensor2=torch.tensor([4,5,6])\n",
    "    tensor_list=list()\n",
    "    tensor_list.append(tensor1)\n",
    "    tensor_list.append(tensor2)\n",
    "    final_tensor=torch.stack(tensor_list)  ###\n",
    "    print('tensor_list:',tensor_list, '  type:',type(tensor_list))\n",
    "    print('final_tensor:',final_tensor, '  type',type(final_tensor))\n",
    "    pass\n",
    "if __name__=='__main__':\n",
    "    listToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6c17d5-9703-42be-a893-773b05bea37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e05f55-1aa7-4a2c-9c75-a1e3ab0872e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f50eeb-d06d-4277-80e1-026fecc54cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "grad_outputs = torch.eye(100000).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9513d9c5-1c75-42ea-9677-19fb16a2a116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ddfb98-de26-4d74-9df6-a983f616863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.line1=nn.Linear(16,8)\n",
    "        self.line2 =nn.Linear(8,10)\n",
    "        self.line3 = nn.Linear(10,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.line1(x)\n",
    "        x = self.line2(x)\n",
    "        x = self.line3(x)\n",
    "        out = self.sigmoid(x)\n",
    "        return out\n",
    "    def grad(self,pred):\n",
    "        pass\n",
    "        #vmap(grad)(pred)\n",
    "        #pred=self(x)\n",
    "        #grad=torch.autograd.grad(outputs=,grad_outputs=pred,inputs=net.parameters(),is_grads_batched=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ce4ea2-7763-4bbd-85d8-4f066d831631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foward: 0.0483553409576416\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\") #(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "inputs = torch.rand(50000,16)\n",
    "inputs.requires_grad=True\n",
    "labels = torch.rand(50000,1)*10//5\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "st1=time.time()\n",
    "outputs = net(inputs).view(-1)\n",
    "end1=time.time()\n",
    "dtime1=end1-st1\n",
    "print(\"foward:\",dtime1)\n",
    "\n",
    "#loss = criterion(outputs, labels)\n",
    "#grad=torch.autograd.grad(outputs=outputs,inputs=inputs,grad_outputs=grad_outputs)\n",
    "\n",
    "#st2=time.time()\n",
    "#loss.backward()\n",
    "#end2=time.time()\n",
    "#dtime2=end2-st2\n",
    "#print(\"backward:\",dtime2)\n",
    "#optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc436ce-80eb-4691-a391-fc0eb8f2e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea0ad8dd-5ed6-4c6e-adf7-753f0fac44f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'vmap' from 'torch' (/home/yufan/anaconda3/envs/pscpu/lib/python3.7/site-packages/torch/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8014/572977832.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvmap\u001b[0m\u001b[0;31m# Setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgrad_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mst2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'vmap' from 'torch' (/home/yufan/anaconda3/envs/pscpu/lib/python3.7/site-packages/torch/__init__.py)"
     ]
    }
   ],
   "source": [
    "from torch import vmap# Setup\n",
    "def get_grad(v):\n",
    "    return torch.autograd.grad(outputs, net.parameters(), v,retain_graph=True)\n",
    "grad_outputs = torch.eye(50000).to(device)    \n",
    "st2=time.time()\n",
    "grad_vmap = vmap(get_grad)(grad_outputs)\n",
    "end2=time.time()\n",
    "dtime2=end2-st2\n",
    "print(\"backward:\",dtime2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494abd6c-7112-4a4d-9f06-d252ea53c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "st3=time.time()\n",
    "for i in range(10000):\n",
    "    net.zero_grad() \n",
    "    outputs[i].backward(retain_graph=True)\n",
    "end3=time.time()\n",
    "dtime3=end3-st3\n",
    "print(\"backward:\",dtime3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded32a9b-d6d1-4667-877d-5a4ece246033",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad0 = torch.autograd.grad(outputs[0], net.parameters() ,allow_unused=True,retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526af822-bd1a-4024-b513-26d5249cc1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad0[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939cd40-907f-4ceb-9565-1f26420c28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad() \n",
    "outputs[99].backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2be804-f2d3-4909-ae3e-189fb0cd8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [x.grad.view(-1) for x in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbbff9a-a7d4-48ad-ba83-0d394df59b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0].reshape(8,16) == grad_vmap[0][99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c555e8b-66c3-471d-a0ef-ed90d12cf0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553a334-27cd-4ff8-872e-c32b495b7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "100000000000/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbdfa42-d1ec-4274-b772-b8f76d1e8f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd5a990-dd2a-4517-a499-008c055f3824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d134954c-6377-42be-8d5e-401c8831e602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf88d82-6b13-40e9-8a89-c5078dacf0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数\n",
    "def fn(x):\n",
    "    return x * x * x\n",
    "\n",
    "# 创建一个输入向量\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# 计算向量雅可比积\n",
    "v = torch.tensor([1.0, 1.0])\n",
    "jvp = torch.autograd.functional.vjp(net.foward, inputs, v)\n",
    "\n",
    "# 输出结果\n",
    "print(jvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ce872-b4e5-4d74-b5df-ff10947e016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad(inputs):\n",
    "    param = net.parameters()\n",
    "    y = net(inputs)\n",
    "    return torch.autograd.grad(y, param, )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0767a6a-7dcf-4261-ad9c-77c773e3f577",
   "metadata": {},
   "outputs": [],
   "source": [
    " vmap(get_grad)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5104a398-d766-4b74-9028-ab35e4bc51ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15045cc4-0cf9-47e7-ab51-45a54c0ec2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "st =time.time()\n",
    "for i in range(10000):\n",
    "    net(inputs[i].unsqueeze(0)\n",
    "end = time.time()\n",
    "dtime = end-st\n",
    "print(dtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361bf5d1-3c1f-4a9b-bcbb-954ccbaa44e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "st2=time.time()\n",
    "for i in range(100000):\n",
    "    grad=torch.autograd.grad(outputs=f_t,inputs=self.estimator.parameters())\n",
    "    #loss.backward(retain_graph=True) #retain_graph=True  create_graph=True\n",
    "    #grad = torch.cat([w.grad.detach().flatten()  for w in net.parameters() if w.requires_grad])\n",
    "    #print(grad.shape)\n",
    "    net.zero_grad()\n",
    "end2=time.time()\n",
    "dtime2=end2-st2\n",
    "print(\"backward:\",dtime2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c9126-0948-4145-b388-c89e3e8dcde8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf31e5-af0d-4ade-8af3-9cdecab0402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([w.grad.detach().flatten()  for w in net.parameters() if w.requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e57c8a-4ecd-42da-be8b-6d0d4da53482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import vmap# Setup\n",
    "N = 5\n",
    "def f(x):\n",
    "    return x ** 2\n",
    "\n",
    "x = torch.randn(N, requires_grad=True)\n",
    "y = f(x)\n",
    "basis_vectors = torch.eye(N)\n",
    "def get_vjp(v):\n",
    "    return torch.autograd.grad(y, x, v)[0]\n",
    "\n",
    "jacobian_vmap = vmap(get_vjp)(basis_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f597530-374c-422c-a8aa-34291853fe19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac1dad3-07b0-420c-a747-602144c15dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b536d5-6b37-4764-83c5-9280fb94317f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408d9cf-aefd-447b-9e17-ca3aa89fe2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d34a9f-6791-496f-ac5d-fdb5f32a929b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6393e-55d0-4c12-b0f3-dfb4ed349189",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(inputs)\n",
    "print(outputs.shape)\n",
    "for i in range(4):\n",
    "    outputs[i].backward(retain_graph=True)\n",
    "    print(\"line.weight.grad = \",net.line.weight.grad)\n",
    "    net.zero_grad()\n",
    "    #print(\"line.weight.grad = \",net.line.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f314abb-c9f1-4603-a816-adbfde48950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 构建一个简单的计算图\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = x.pow(2)\n",
    "z = y.sum()\n",
    "\n",
    "# 第一次反向传播\n",
    "for i in range(5):\n",
    "    z.backward(retain_graph=True)\n",
    "    print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b9415-d287-4260-b119-6ed7c60a5060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b74d25-c6a0-404c-81d5-5fd19f733d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0990d9ac-ce92-4aea-8611-76de0080d864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17f3bae-c18f-4a56-b717-f56215ee84ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474efe45-724c-456b-8df3-6b999582326b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf58ec-24bc-4f0a-986a-e417940c134b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8b937-a41e-4fdb-9cfd-691ecf03efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import vmap# Setup\n",
    "N = 5\n",
    "\n",
    "def f(x,w):\n",
    "    y = torch.matmul(x,w)\n",
    "    return y\n",
    "    \n",
    "w = torch.rand(10,1)\n",
    "w.requires_grad=True\n",
    "    \n",
    "x = torch.randn(4,10)\n",
    "x.requires_grad=True\n",
    "y = f(x,w).view(-1)\n",
    "\n",
    "basis_vectors = torch.eye(4)\n",
    "def get_vjp(v):\n",
    "    return torch.autograd.grad(y, w, v)[0]\n",
    "\n",
    "jacobian_vmap = vmap(get_vjp)(basis_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa50fa8-76bf-419b-b71d-663fda853e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06f7ee-068e-4715-a9a8-8b4af097c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5547ad2-3f36-4ae1-84c5-62c91e26f632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e49c0ea-0548-4c8d-84a1-f2e91f29d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential approach\n",
    "jacobian_rows = [torch.autograd.grad(y, x, v, retain_graph=True)[0]\n",
    "                 for v in basis_vectors.unbind()]\n",
    "jacobian = torch.stack(jacobian_rows)\n",
    "\n",
    "# Using `vmap`, we can vectorize the whole computation, computing the\n",
    "# Jacobian in a single call to `autograd.grad`.\n",
    "def get_vjp(v):\n",
    "    return torch.autograd.grad(y, x, v)[0]\n",
    "\n",
    "jacobian_vmap = vmap(get_vjp)(basis_vectors)\n",
    "assert torch.allclose(jacobian_vmap, jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa66afed-60a7-4ed8-89bf-1647d485c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "batch_size, feature_size = 3, 5\n",
    "weights = torch.randn(feature_size, requires_grad=True)\n",
    "\n",
    "# Note that model doesn't work with a batch of feature vectors because\n",
    "# torch.dot must take 1D tensors. It's pretty easy to rewrite this\n",
    "# to use `torch.matmul` instead, but if we didn't want to do that or if\n",
    "# the code is more complicated (e.g., does some advanced indexing\n",
    "# shenanigins), we can simply call `vmap`. `vmap` batches over ALL\n",
    "# inputs, unless otherwise specified (with the in_dims argument,\n",
    "# please see the documentation for more details).\n",
    "def model(feature_vec):\n",
    "    # Very simple linear model with activation\n",
    "    return feature_vec.dot(weights).relu()\n",
    "\n",
    "examples = torch.randn(batch_size, feature_size)\n",
    "result = torch.vmap(model)(examples)\n",
    "expected = torch.stack([model(example) for example in examples.unbind()])\n",
    "assert torch.allclose(result, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58f25c-ec3d-441d-b6f2-df7f661e221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d3888-1211-4a12-bb64-fe02c11d4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# 定义一个函数\n",
    "def fn(x):\n",
    "    w = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "    return torch.dot(x*x,w)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.line1=nn.Linear(16,8)\n",
    "        self.line2 =nn.Linear(8,10)\n",
    "        self.line3 = nn.Linear(10,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.line1(x)\n",
    "        x = self.line2(x)\n",
    "        x = self.line3(x)\n",
    "        out = self.sigmoid(x)\n",
    "        return out\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "inputs = torch.rand(100000,16)\n",
    "labels = torch.rand(100000,1)*10//5\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# 创建一个输入向量\n",
    "#x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# 计算向量雅可比积\n",
    "v = torch.ones(100000,1).to(device)\n",
    "jvp = torch.autograd.functional.vjp(net.forward, list(net.parameters()),v)[1]\n",
    "\n",
    "# 输出结果\n",
    "print(jvp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa31a7-dc45-407b-964d-4934d697ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#x = torch.tensor([2.0, 3.0,-1], requires_grad=True)\n",
    "#w = torch.tensor([2.0, 3.0,1],requires_grad=True)\n",
    "#y = x ** 3+ w*x  # 定义一个计算图\n",
    "x = torch.randn(4,10)\n",
    "x.requires_grad=True\n",
    "w = torch.rand(10,1)\n",
    "w.requires_grad=True\n",
    "y = torch.matmul(x,w)\n",
    "print(y)\n",
    "grad_outputs = torch.ones(y.shape)  # 批次的梯度张量\n",
    "\n",
    "grad = torch.autograd.grad(y, w,grad_outputs=grad_outputs) \n",
    "\n",
    "print(grad)  # 输出梯度值，为 [4.0, 12.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8eb27-e88f-4865-8535-8ce6ca8e32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802dda0b-253a-4599-829c-4328f48a0061",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(x,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fcaa7-99ca-46d0-95ad-e2e0c77b3785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba5e2a0-f909-4ce1-8ca2-8fadbafde538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca825c9-4257-4c41-9feb-86e562edf88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(x):\n",
    "    w = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "    return torch.dot(x*x,w)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.line1=nn.Linear(16,8)\n",
    "        self.line2 =nn.Linear(8,10)\n",
    "        self.line3 = nn.Linear(10,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.line1(x)\n",
    "        x = self.line2(x)\n",
    "        x = self.line3(x)\n",
    "        out = self.sigmoid(x)\n",
    "        return out\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Net()\n",
    "\n",
    "inputs = torch.rand(1000,16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f546f78-b6f1-41ae-8666-d97ecbf93acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd.functional as F\n",
    "\n",
    "def model(input, weight):\n",
    "    weight = \n",
    "    return net(input)\n",
    "                     \n",
    "def grad_sample(sample):\n",
    "    return F.vjp(lambda weight: model(inputs, weight), weight)[1]\n",
    "\n",
    "# 示例调用\n",
    "sample = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "weight = torch.tensor([0.1, 0.2, 0.3], dtype=torch.float32)\n",
    "\n",
    "gradient = grad_sample(inputs)\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237891a8-897c-4102-a12f-df414b7d4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda weight: model(sample, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dada0b-7def-464f-83c4-9c23e64a8dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.line1 = nn.Linear(16, 8)\n",
    "        self.line2 = nn.Linear(8, 10)\n",
    "        self.line3 = nn.Linear(10, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.line1(x)\n",
    "        x = self.line2(x)\n",
    "        x = self.line3(x)\n",
    "        out = self.sigmoid(x)\n",
    "        return out\n",
    "\n",
    "# 手动实现的模型\n",
    "class ManualNet:\n",
    "    def __init__(self):\n",
    "        self.weights = {\n",
    "            'line1.weight': torch.randn(8, 16),\n",
    "            'line1.bias': torch.randn(8,1),\n",
    "            'line2.weight': torch.randn(10, 8),\n",
    "            'line2.bias': torch.randn(10,1),\n",
    "            'line3.weight': torch.randn(1, 10),\n",
    "            'line3.bias': torch.randn(1,1)\n",
    "        }\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = torch.matmul(self.weights['line1.weight'], x.t()) \n",
    "        print(x.shape)\n",
    "        x = x + self.weights['line1.bias']\n",
    "        print(x.shape)\n",
    "        x = torch.matmul(self.weights['line2.weight'], self.sigmoid(x)) + self.weights['line2.bias']\n",
    "        x = torch.matmul(self.weights['line3.weight'], self.sigmoid(x)) + self.weights['line3.bias']\n",
    "        out = self.sigmoid(x)\n",
    "        return out.t()\n",
    "\n",
    "# 示例调用\n",
    "inputs = torch.randn(1, 16)\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a7f3e3-7c54-4695-bc07-81fb09e6b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_net = ManualNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ffb88-a793-4b60-a72f-7145f41cc9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_net.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53847c6-4d2b-4141-8758-f92397df074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net(inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e2eb7-99ae-4fcf-aa94-288cf282fca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
